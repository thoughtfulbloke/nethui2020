---
title: "2020 NetHui"
author: "David Hood"
output: 
  html_document: 
    keep_md: yes
    toc: yes
---

```{r setup, include=FALSE, cache=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(fig.height = 8)
knitr::opts_chunk$set(fig.width= 12)
knitr::opts_chunk$set(fig.retina=3)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

```

```{r, load_libraries, warning=FALSE, message=FALSE, cache=FALSE}
library(tm)
library(readr)
library(dplyr)
library(tidyr)
library(tidytext) # also need textdata
library(syn)
library(ggplot2)
library(ggthemes)

```

```{r, theme_info}
theme_videosize <- theme(axis.text = element_text(size = 14),
                         axis.title = element_text(size = 14),
                         legend.text = element_text(size = 14),
                         legend.title = element_text(size = 14),
                         strip.background = element_rect(fill= "#FFFFFF", colour="#EFEFEF"),
        strip.placement = "inside",
        panel.grid = element_blank(),
        panel.background = element_rect(fill = "#FFFFFF", colour = "#FFFFFF"),
        panel.spacing = unit(1.5, "lines"),
        plot.background = element_rect(fill = "#FAFAFA", colour = NA)
)
```

## Social Media Election Trends

(actually Twitter)

(actually about how can we measure stuff)

(actually about what do we mean talking about stuff)

**Sources:**

- 29064 politician/party tweets from the last 6 months
- 114838 replies to those tweets
- 176000 recent likes of highly active repliers
- 2687383 additional tweets mentioning polticians & parties in the last year (in additon to the last 6 months of replies).

Readable graphs: https://github.com/thoughtfulbloke/nethui2020

(code in .Rmd file)


```{r, load_data}
pols <- read_csv("../data_sources/polTweets.csv", col_types = cols(
  status_id = col_character(),
  created_at = col_datetime(format = ""),
  screen_name = col_character(),
  text = col_character(),
  favorite_count = col_double()
))
colnames(pols) <- paste0("pol_", colnames(pols))

reps <- read_csv("../data_sources/replies.csv", col_types = cols(
  status_id = col_character(),
  created_at = col_datetime(format = ""),
  screen_name = col_character(),
  text = col_character(),
  reply_to_status_id = col_character(),
  user_id = col_character()
))
colnames(reps) <- paste0("rep_", colnames(reps))

context <- read_csv("../data_sources/what_is_who.csv",col_types=cols(
  screenName = col_character(),
  Surname..Firstname = col_character(),
  Party = col_character(),
  Electorate = col_character(),
  personOrParty = col_character(),
  MFP = col_character()
))
colnames(context) <- paste0("detail_", colnames(context))

likes_what <- read_csv("../data_sources/addlikes.csv", col_types=cols(
  favorited_by = col_character(),
  Labour = col_double(),
  National = col_double(),
  Green = col_double(),
  ACT = col_double(),
  NZF = col_double()
))
colnames(likes_what) <- paste0("liking_", colnames(likes_what))

polimentions <- read_csv("../data_sources/mentions_totals.csv", col_types=cols(
  screen_name = col_character(),
  in_set = col_double(),
  fromtweet = col_double(),
  totweet = col_double()
))
colnames(polimentions) <- paste0("ment_", colnames(polimentions))

bios <- read_csv("../data_sources/repbios.csv", 
                 col_types = cols_only(user_id = col_character()))
colnames(bios) <- paste0("bio_", colnames(bios))
nrc <- get_sentiments("nrc")
```


## Sentiment of replies

Average sentiment of replies to political tweets by account replied to

```{r, trust, warning=FALSE, message=FALSE}
p3 <- reps %>%
  select(rep_status_id, rep_reply_to_status_id, rep_text) %>%
  unnest_tokens(word,rep_text, token = "tweets") %>%
  inner_join(nrc, by = "word") %>% 
  group_by(rep_reply_to_status_id, rep_status_id) %>%
  summarise(joy_trust= sum(sentiment == "joy") + sum(sentiment == "trust"),
            disgust_anger= sum(sentiment == "disgust") + sum(sentiment == "anger")) %>%
  ungroup() %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  group_by(detail_MFP, detail_Surname..Firstname) %>% 
  summarise(replies=n(),
            jt_da = mean(joy_trust) - mean(disgust_anger)) %>%
  ungroup() %>%
  mutate(gender = case_when(detail_MFP == "m" ~"male",
                            detail_MFP == "f" ~"female",
                            detail_MFP == "p" ~"party")) 
```
```{r, p3graph, cache=FALSE}

  ggplot(p3, aes(x=jt_da, y=replies, shape=gender, colour=gender)) + geom_point() +
  theme_tufte() + scale_color_colorblind() + theme_videosize +
  xlab("\nmean(joy + trust) per tweet - mean(disgust + anger) per tweet") +
  ylab("total replies to the acccount\n")

```

The lack of difference is interesting in relation to the negativity seen when checking responses to female politicians in other countries. this graph has also gone slightly more postive since the 2017 election.

## Sentiments of replies

Sentiments per 1000 words in replies to politcal tweets

```{r}
reps %>%
  select(rep_text, rep_reply_to_status_id) %>%
  unnest_tokens(word,rep_text, token = "tweets") %>%
  inner_join(nrc, by = "word") %>% 
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  count(detail_Party, sentiment) %>%
  group_by(detail_Party) %>%
  mutate(per_1000_words = 1000 * n / sum(n)) %>%  ungroup() %>%
  select(sentiment, per_1000_words, Party=detail_Party) %>%
  ggplot(aes(x=sentiment, y=per_1000_words, fill=Party)) + geom_col() +
  scale_colour_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +  
  scale_fill_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +
  theme_tufte() + theme_videosize + xlab("\nSentiment") + ylab("Frequency\n") +
  facet_wrap(~ Party, ncol=2) + theme(axis.text.x = element_text(angle = 90))

```

this is an example of a fairly standard sentiment graph aggregating repsonses to accounts associated with different poltical parties. The profound lack of difference across the responders is of note.

## Sentiments of party tweets showing unmatched words
```{r}
reps %>%
  select(rep_text, rep_reply_to_status_id) %>%
  unnest_tokens(word,rep_text, token = "tweets") %>%
  left_join(nrc, by = "word") %>%
  mutate(sentiment = ifelse(is.na(sentiment), "unknown term", sentiment)) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  count(detail_Party, sentiment) %>%
  group_by(detail_Party) %>%
  mutate(per_1000_words = 1000 * n / sum(n)) %>% ungroup() %>%
  select(sentiment, per_1000_words, Party=detail_Party) %>%
  ggplot(aes(x=sentiment, y=per_1000_words, fill=Party)) + geom_col() +
  scale_colour_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +  
  scale_fill_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +
  theme_tufte() + theme_videosize + xlab("\nSentiment") + ylab("Frequency\n") +
  facet_wrap(~ Party, ncol=2) + theme(axis.text.x = element_text(angle = 90))

```

But there are issues with using sentiment analysis well, or at all. If we include the number of unknown terms, the differences we were seeing (that were already insignificant) become overwhelmingly insignificant.


## Adding Synonyms and stemming


```{r}
syno <- unlist(syns(nrc$word))
synod <- data.frame(term = names(syno), extend=unname(syno), stringsAsFactors = FALSE)
synod$word <- gsub("[1234567890]*","",synod$term)
nrc_plus <- synod %>% inner_join(nrc, by="word") %>% 
  select(word=extend, sentiment) %>% distinct()
nrc_plus$stem <- stemDocument(nrc_plus$word, language = "english")
nrc_stemplus <- nrc_plus %>% select(word=stem, sentiment) %>% distinct()

reps %>%
  select(rep_text, rep_reply_to_status_id) %>%
  unnest_tokens(word,rep_text, token = "tweets") %>%
  mutate(word = stemDocument(word, language = "english")) %>%
  left_join(nrc_stemplus, by = "word") %>% 
  mutate(sentiment = ifelse(is.na(sentiment), "unknown term", sentiment)) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  count(detail_Party, sentiment) %>%
  group_by(detail_Party) %>%
  mutate(per_1000_words = 1000 * n / sum(n)) %>% ungroup() %>%
  select(sentiment, per_1000_words, Party=detail_Party) %>%
  ggplot(aes(x=sentiment, y=per_1000_words, fill=Party)) + geom_col() +
  scale_colour_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +  
  scale_fill_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +
  theme_tufte() + theme_videosize + xlab("\nSentiment") + ylab("Frequency\n") +
  facet_wrap(~ Party, ncol=2) + theme(axis.text.x = element_text(angle = 90))



```

We can apply tricks to reduce the unknowns, such as using synonyms and stemming (removing the suffixes of words when matching) however what we are doing is extending the range of a limited set of lookup values.

## Most trusting Reply

This is the tweet that, by far, scores as showing the most trust:

<hr>

```{r}
max_trust <- reps %>%
  select(rep_status_id, rep_text) %>%
  mutate(t2=rep_text) %>%
  unnest_tokens(word,rep_text, token = "tweets") %>%
  inner_join(nrc %>% filter(sentiment == "trust"), by = "word") %>%
  count(rep_status_id, t2) %>%
  arrange(desc(n)) %>%
  slice(1)
```

<div style="width:66%;text-align:left;">
`r max_trust$t2[1]`
</div>

<hr>

Because it is all based on a limited set of sentiment lookup matches, it has no knowledge of local context, nor does it cope with the limited character count of twitter leading people to talk about the thing, rather than using metaphors in extended discussion. 


## Ratioing by party

Replies vs likes, for every tweet made by a political account

(most extreme 2 tweets for each account removed)

```{r}
reps %>%
  count(rep_reply_to_status_id) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  arrange(pol_screen_name, desc(pol_favorite_count)) %>%
  group_by(pol_screen_name) %>%
  slice(-1) %>% ungroup() %>%
  arrange(pol_screen_name, desc(n)) %>%
  group_by(pol_screen_name) %>%
  slice(-1) %>% ungroup() %>%
  select(n, pol_favorite_count, Party=detail_Party) %>%
  ggplot(aes(x=n, y=pol_favorite_count, colour = Party)) + 
  geom_jitter(alpha=0.8) + facet_wrap(~Party, ncol=2) +
  scale_colour_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) + 
  scale_fill_manual(values =c("#FDE401","#098137", "#D82A20","#00529F", "#000000")) +
  theme_tufte() + theme_videosize + xlab("\nReplies") + ylab("\nLikes")
               
```

Yes, NZ Twitter is mostly to the left of parties on the right, but so are most voters.

## Ratio by gender

```{r}
reps %>%
  count(rep_reply_to_status_id) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  arrange(pol_screen_name, desc(pol_favorite_count)) %>%
  group_by(pol_screen_name) %>%
  slice(-1) %>% ungroup() %>%
  arrange(pol_screen_name, desc(n)) %>%
  group_by(pol_screen_name) %>%
  slice(-1) %>% ungroup() %>%
  mutate(gender = case_when(detail_MFP == "m" ~"male",
                            detail_MFP == "f" ~"female",
                            detail_MFP == "p" ~"party")) %>%
  ggplot(aes(x=n, y=pol_favorite_count, shape=gender, colour=gender)) + 
  geom_jitter(alpha=0.8) + facet_wrap(~gender, ncol=2) +
  scale_colour_colorblind() +
  theme_tufte() + theme_videosize + xlab("\nReplies") + ylab("\nLikes")

```

There are no particularly dramatic differences if you look at ratioing by gender (which is in line with other indicators)

## ratio by gender 90% quartile
```{r}
reps %>%
  count(rep_reply_to_status_id) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  mutate(ratio = n/pol_favorite_count) %>%
  arrange(pol_screen_name, ratio) %>%
  group_by(pol_screen_name) %>%
  mutate(dectile = ntile(ratio,10)) %>%
  ungroup() %>% filter(dectile==10) %>%
  mutate(gender = case_when(detail_MFP == "m" ~"male",
                            detail_MFP == "f" ~"female",
                            detail_MFP == "p" ~"party")) %>%
  ggplot(aes(x=n, y=pol_favorite_count, shape=gender, colour=gender)) + 
  geom_jitter(alpha=0.8) + facet_wrap(~gender, ncol=2) +
  scale_colour_colorblind() +
  theme_tufte() + theme_videosize + xlab("\nReplies") + ylab("\nLikes")
               
```

Taking the 10% most ratio'd tweets, there is no strong gender difference among the most engaged with tweets.

## Repliers likes of parties

```{r}
likes_what %>%
  mutate(lb=liking_Labour > 0,
         nt=liking_National > 0,
         gr=liking_Green > 0,
         nz=liking_NZF > 0,
         ac= liking_ACT > 0,
         parties = lb + nt + gr+nz+ac) %>% 
  ggplot(aes(x=parties)) + geom_bar(fill="orange") + theme_tufte() + theme_videosize
```

Of those most replying to poltician's tweets, who liked at least one tweet from a political account, most people liked tweets associated from two or more parties. Which, again, suggests a lack of polarisation.

## liking and replying

```{r}
loud <- reps %>%
  select(rep_screen_name, rep_reply_to_status_id) %>%
  inner_join(pols, by=c("rep_reply_to_status_id" = "pol_status_id")) %>%
  count(pol_screen_name, rep_screen_name) %>%
  arrange(pol_screen_name, desc(n)) %>%
  group_by(pol_screen_name) %>%
  slice(1:10) %>%
  ungroup() 

loud %>% distinct() %>% inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  select(1:3,5,8) %>%
  left_join(likes_what, by=c("rep_screen_name" = "liking_favorited_by")) %>%
  mutate(liking_Labour = ifelse(is.na(liking_Labour), 0, liking_Labour),
         liking_National = ifelse(is.na(liking_National), 0, liking_National),
         liking_Green = ifelse(is.na(liking_Green), 0, liking_Green),
         liking_ACT = ifelse(is.na(liking_ACT), 0, liking_ACT),
         liking_NZF = ifelse(is.na(liking_NZF), 0, liking_NZF),
         n = as.double(n)) %>% 
  mutate(ally = case_when(detail_Party == "Labour Party" & liking_Labour > 0 ~ n,
                          detail_Party == "National Party" & liking_National > 0 ~ n,
                          detail_Party == "Green Party" & liking_Green > 0 ~ n,
                          detail_Party == "ACT Party" & liking_ACT > 0 ~ n,
                          detail_Party == "NZ First Party" & liking_NZF > 0 ~ n,
                          TRUE ~ 0),
         not_ally = case_when(detail_Party == "Labour Party" & liking_Labour == 0 ~ n,
                          detail_Party == "National Party" & liking_National == 0 ~ n,
                          detail_Party == "Green Party" & liking_Green == 0 ~ n,
                          detail_Party == "ACT Party" & liking_ACT == 0 ~ n,
                          detail_Party == "NZ First Party" & liking_NZF == 0 ~ n,
                          TRUE ~ 0)) %>%
  select(1,2,4,5,11,12) %>%
  group_by(pol_screen_name, detail_MFP, detail_Party) %>% 
  summarise(public_friend = sum(ally),
            not_public_friend = sum(not_ally),
            main_replies = (public_friend + not_public_friend),
            percent_public_friend = 100 * public_friend / main_replies) %>% 
  ungroup() %>% 
  mutate(gender = case_when(detail_MFP == "m" ~"male",
                            detail_MFP == "f" ~"female",
                            detail_MFP == "p" ~"party")) %>%
  ggplot(aes(y= percent_public_friend, x=main_replies, shape=gender, colour=gender)) +
  geom_jitter(alpha=0.8) +
  scale_colour_colorblind() +
  theme_tufte() + theme_videosize + xlab("\nTotal replies") + 
  ylab("Percent replies to tweets from likers")


  


```


## stalking

Of those gone from Twitter, 
percent of tweets to politicians by supposed total tweets


```{r}
reps %>% 
  anti_join(bios, by=c("rep_user_id" = "bio_user_id")) %>%
  select(rep_screen_name) %>%
  inner_join(polimentions, by=c("rep_screen_name" = "ment_screen_name")) %>%
  mutate(tweets_in_span = log10(ment_totweet - ment_fromtweet +1),
         percent_poltical = 100 *ment_in_set / (ment_totweet - ment_fromtweet +1)) %>%
  ggplot(aes(x=tweets_in_span, y=percent_poltical)) + geom_point(size=0.5,alpha=0.8) +
  theme_tufte() + theme_videosize +
  xlab("\nLog (base 10) supposed total tweets") + 
  ylab("Tweets to political accounts as percent of total\n") +
  annotate("segment", x=0, xend=5,y=100,yend=100, colour="red")
```

By dividing the number of captured tweets by the supposed number (actually undeleted number) of tweets made, you can see the range of people reponded to. And an estimate of the number of tweets being deleted. Either one may be an early indicator of an offensive/stalky account.

## non-sequiters

The percentage of words the reply has in common with the original tweet

```{r}
combos <- pols %>%
  inner_join(reps, by=c("pol_status_id" = "rep_reply_to_status_id")) %>%
  select(rep_status_id, pol_screen_name, pol_text, rep_text) 
sameness <- function(x, convos = combos){
  pol = tryCatch(suppressMessages(unnest_tokens(convos[x,], word, pol_text, token = "tweets")), error = function(e) return(NULL))
  rpl = tryCatch(suppressMessages(unnest_tokens(convos[x,], word, rep_text, token = "tweets")), error = function(e) return(NULL))
  sum(rpl$word %in% pol$word) / length(rpl$word)
}
prop_same = sapply((1:nrow(combos)),sameness)
combos$sameness = prop_same *100
combos <- combos %>%
  inner_join(context, by=c("pol_screen_name" = "detail_screenName")) %>%
  select(pol_screen_name, detail_Party, detail_MFP, sameness)
```

```{r}
combos %>%
    mutate(gender = case_when(detail_MFP == "m" ~"male",
                            detail_MFP == "f" ~"female",
                            detail_MFP == "p" ~"party")) %>%
  ggplot(aes(x=sameness, colour=gender)) + geom_density() +
  theme_tufte() + theme_videosize + xlab("\nPercentage of same words")
```

Normal conversation has between 10% and 50% of the same words, so a reply with nothing in common suggests the reply is not to engage with the topic. These numbers could be further adjusted with synonyms etc.


